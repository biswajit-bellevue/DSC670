{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b95164-6963-4658-ba23-867bfd9bf8bd",
   "metadata": {},
   "source": [
    "## Assignment Week 6\n",
    "\n",
    "### RAG using Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5cee83-c623-463b-8456-3e7b9fb39d48",
   "metadata": {},
   "source": [
    "RAG is a technique of optimizing the output of a large language models that involves referencing a knowledge outside of its training data sources before generating a response. RAG can be used to augment the LLM knowledge with information that was not part of the original training data. In the below activity RAG approach is used with OpenAPI LLM model (chatgp-4o-mini) which have a knowledge cut-off date of `July-2024`. Hence, gpt-4o-mini model will not be able to accurately answer information about events that happened after the `cut-off` date. However, it may still make up some answer even it was not part of training data, but that may be false or not trustworthy. Using, RAG approach relevant and trustworthy response can be received by passing the additional data in the context.\n",
    "\n",
    "For this exercise, question about wildfires that happened in January 2025 will be sent to LLM `without RAG approach`, and the same questions will be again asked by providing information in the context about California 2025 wildfires from Wikipedia web page `January 2025 Souther California` using `RAG approach`.  Then the responses will be investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc21c1df-eef0-4599-8531-f5a2d4df6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9b6b32-abd9-4f9c-b875-98ba1469b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd5dee0-7959-4fd9-a85b-f768ab69150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get api key from file\n",
    "with open(\"../../../apikeys/openai-keys.json\", \"r\") as key_file:\n",
    "    api_key = json.load(key_file)[\"default_api_key\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e6a806b-6edd-4b51-a41a-9facdb651bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de71b30c-6458-450a-92db-73c7fd0938dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from uuid import uuid4,uuid5\n",
    "import uuid\n",
    "from langchain_core.documents import Document\n",
    "import tiktoken as tk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c98a3be8-6c07-410c-949b-0a2e7c88f656",
   "metadata": {},
   "source": [
    "The chunks are converted to vector embeddings and stored in a vector database which enables retrieval of relevant information from the knowledge base matching the user query and sent as context in the prompt to LLM.\n",
    "\n",
    "Open AI's [text-embedding-3-small][1] embedding model is used to generate the embeddings. it is important to note that this model is not Gen AI model, instead it is used to generates vector embedings. \n",
    "\n",
    "[1]:https://platform.openai.com/docs/guides/embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0685a6-636f-43e9-87c6-74d18f81ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df31f491-a334-490b-96f9-5e20b453b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"ehr_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./vector-stores/chroma_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862245db-74e6-43d5-aa7c-1d28fa9ae8b0",
   "metadata": {},
   "source": [
    "##### Load PDFs page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78ed5716-7dbf-4fe8-ac80-6e308e9810e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d46ce6a-28c9-44f5-bf9e-1ab5bf8b9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(filename):\n",
    "    return filename.split(\"_\")[0].lower(),  str(filename.split(\"_\")[-1].split(\".\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00365511-ec81-42da-a079-47c6771c1b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alexis Sparks_EHR_20250215.pdf']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files = [fnames for fnames in os.listdir(os.path.join(os.getcwd(),\"pdfs\")) if re.search(\".pdf\",fnames)]\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03899883-4670-4c1d-abd2-99042e259d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('alexis sparks', '20250215')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_name, dos = extract_metadata(pdf_files[0])\n",
    "pat_name,dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1976f412-7b7f-44d0-b043-4a732f5e7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(os.path.join(os.getcwd(),\"pdfs\",pdf_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ea45a2f-1f69-4877-9949-3e60334d603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba826a0-469b-41b0-a1c2-5b750a3d12c9",
   "metadata": {},
   "source": [
    "#### use spacy for PHI detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57ab109f-6612-4b9f-b774-ed2dbcc04c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# print(f\"{pages[0].metadata}\\n\")\n",
    "# print(pages[0].page_content)\n",
    "print(len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb5c975d-fd45-42d6-9880-a069e8bf3381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"* Metformin 500 mg twice daily\\n### Health Conditions\\n* Type 2 Diabetes (recently diagnosed)\\n* Obstructive Sleep Apnea (OSA)\\n### Recent Diagnosis\\n* Morbid Obesity\\n* Essential Hypertension\\n* Type 2 Diabetes\\n### Personal Health Assessment\\n* Lifestyle:\\n    * Exercises: Rarely; sedentary lifestyle\\n    * Diet: High in carbohydrates and sugars; minimal fruits and vegetables\\n    * Sleep: 5-6 hours per night, often interrupted\\n    * Stress: Moderate to high due to work and personal life\\n* Tobacco Use: Never smoked\\n* Alcohol Use: Social drinker, approximately 2-3 drinks per week\\n* Occupation: Office manager, primarily desk job with limited physical activity\\n### Physician's Notes\\n* Patient presents with a significant risk for cardiovascular disease given his morbid obesity and\\nhypertension. Discussed the importance of lifestyle modifications including diet changes and\\nincreased physical activity. Referral to a dietitian provided to assist with meal planning.\\nRecommended follow-up in 3 months for reassessment of weight and blood pressure. Consider\\neligibility for bariatric surgery based on weight loss progress. Monitoring of blood\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50f205b4-3323-4a8d-bf2a-7d22772eec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact_dob(page_content):\n",
    "    match = None\n",
    "    if re.search(\"DOB\",page_content):\n",
    "        match = re.search(\"DOB\",page_content)\n",
    "    elif re.search(\"Date Of Birth\",page_content):\n",
    "        match = re.search(\"Date Of Birth\",page_content)\n",
    "    else:\n",
    "        match = None\n",
    "    if match:\n",
    "        dob_start = match.span()[1]+1\n",
    "        dob = page_content[dob_start: dob_start+11]\n",
    "        page_content = (page_content[0:dob_start]\n",
    "                        +  \"<PHI>\"\n",
    "                        + \"\".join([\"X\" for _ in page_content[dob_start: dob_start+11]])\n",
    "                        + \"</PHI> \"\n",
    "                        + page_content[dob_start+11:]\n",
    "                       )\n",
    "    return page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4e43254-b9b8-4383-94c4-28e709c1ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact_name(page_content):\n",
    "    match = re.search(\"Name\",page_content)\n",
    "    if match:\n",
    "        name_split  = page_content[match.span()[0]+6:].split(\"*\")\n",
    "        name_length = len(name_split[0])\n",
    "        page_content = (page_content[0:match.span()[0]+6] + \n",
    "                        \"<PHI>\" + \n",
    "                        \"\".join([\"X\" for _ in range(name_length)]) \n",
    "                        + \"</PHI> \"\n",
    "                        + \" \".join([ x for x in name_split[1:]])\n",
    "                       )\n",
    "    return page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7418a469-9060-49b0-b785-5d7884260c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact_name_references(page_content):\n",
    "    doc = nlp(page_content.replace(\"\\n\",\"\"))\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        # print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "        if ent.label_ in [\"PERSON\"]:\n",
    "            \n",
    "            page_content = (page_content[0:ent.start_char]\n",
    "                    +  \"<PHI>\"\n",
    "                    + \"\".join([\"X\" for _ in page_content[ent.start_char:ent.end_char] ])\n",
    "                    + \"</PHI> \"\n",
    "                    + page_content[ent.end_char+11:]\n",
    "                   )\n",
    "        \n",
    "    return page_content  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77bb506d-a64a-4890-b57e-54aaa7c88266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redacted_pages = []\n",
    "# for each_page in pages:\n",
    "#     page_content = each_page.page_content\n",
    "#     page_content = redact_dob(page_content)\n",
    "#     page_content = redact_name(page_content)\n",
    "#     page_content = redact_name_references(page_content)\n",
    "#     redacted_pages.append(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e260b-acb2-471a-8f81-45bdbebd8145",
   "metadata": {},
   "source": [
    "In RAG approach, the additional infomation from knowledge base is first chunked (splitted) and stored as vector embeddings in a vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689dc3f-1a79-43d8-abfc-9046d728481a",
   "metadata": {},
   "source": [
    "1. Perform Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61401c1c-4e99-4bd8-a589-53c182332746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits : 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"###\"],\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap  = 10,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(pages)\n",
    "print(f\"Number of splits : {len(all_splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b5c603d-f5e2-4214-9396-0349a5494057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/biswajitmac/Documents/Biswajit/github/DSC670/ehr/pdfs/Alexis Sparks_EHR_20250215.pdf', 'page': 0}, page_content='* Name: Alexis Sparks\\n* DOB: 1971-01-25\\n* Age: 38\\n* Gender: Male\\n* Patient ID: 123456'),\n",
       " Document(metadata={'source': '/Users/biswajitmac/Documents/Biswajit/github/DSC670/ehr/pdfs/Alexis Sparks_EHR_20250215.pdf', 'page': 0}, page_content='### Vital Signs (Recorded on 2023-10-20)\\n* Blood Pressure: 145/95 mmHg\\n* Heart Rate: 82 bpm\\n* Respiratory Rate: 18 breaths/min\\n* Temperature: 98.6 °F\\n* Oxygen Saturation (SpO2): 98%\\n* BMI: 42.1 kg/m²\\n'),\n",
       " Document(metadata={'source': '/Users/biswajitmac/Documents/Biswajit/github/DSC670/ehr/pdfs/Alexis Sparks_EHR_20250215.pdf', 'page': 0}, page_content='### Family History\\n* Father: Hypertension, Type 2 Diabetes\\n* Mother: Morbid Obesity, Hyperlipidemia\\n* Siblings: One brother with obesity-related health issues\\n'),\n",
       " Document(metadata={'source': '/Users/biswajitmac/Documents/Biswajit/github/DSC670/ehr/pdfs/Alexis Sparks_EHR_20250215.pdf', 'page': 0}, page_content='### Medical History\\n* Chronic Conditions:\\n    * Morbid Obesity\\n    * Hypertension\\n* Previous Surgeries:\\n    * None\\n* Allergies:\\n    * Penicillin (rash)\\n'),\n",
       " Document(metadata={'source': '/Users/biswajitmac/Documents/Biswajit/github/DSC670/ehr/pdfs/Alexis Sparks_EHR_20250215.pdf', 'page': 0}, page_content='### Current Medications\\n* Lisinopril 20 mg daily')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb05098-9ae6-4c68-8267-08d2f95017fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c0f3245-3489-4a29-bf65-c6d524703a08",
   "metadata": {},
   "source": [
    "It is also a good idea to get the number of tokens chunks may consume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e767e92-e90d-49a8-9aa2-c1bca7f90adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_token(split):\n",
    "    encoding = tk.get_encoding(\"cl100k_base\")\n",
    "    encoded_string = encoding.encode(split)\n",
    "    print(f\"Number of total tokens: {len(encoded_string)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57c12c6e-12c9-4cc0-98d0-5bbca8d9dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document_embeddings(chunk, pat_name, dos, split_num):\n",
    "    document_1 = Document(\n",
    "    page_content=chunk,\n",
    "    metadata={\n",
    "        \"patient_name\": pat_name,\n",
    "        \"date_of_service\":dos,\n",
    "        \"version\":\"1.0\"\n",
    "    },\n",
    "    # id=hash(f\"{pat_name}-{dos}-{split_num}\"),\n",
    "    id = uuid5(uuid.NAMESPACE_URL,f\"{pat_name}-{dos}-{split_num}\")\n",
    "    )\n",
    "    \n",
    "    documents = [\n",
    "    document_1,\n",
    "    ]\n",
    "    print(\"--\"*50)\n",
    "    print(document_1.metadata)\n",
    "    print(document_1.page_content)\n",
    "    print(document_1.id)\n",
    "    print(\"--\"*50)\n",
    "    return_ids = vector_store.add_documents(documents=documents)\n",
    "    print(f\"Document id added: {return_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bee75c-c35a-48f6-aeff-57a033446aee",
   "metadata": {},
   "source": [
    "2. Generate embeddings and store embeddings in vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea8514a0-a187-4852-8636-85da9d909a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total tokens: 46\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'patient_name': 'alexis sparks', 'date_of_service': '20250215', 'version': '1.0'}\n",
      "* Name: <PHI>XXXXXXXXXXXXXX</PHI>  DOB:<PHI>XXXXXXXXXXX</PHI> \n",
      "  Age: 38\n",
      "  Gender: Male\n",
      "  Patient ID: 123456\n",
      "77c69a1c-e938-53af-b662-7578face43cc\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document id added: ['77c69a1c-e938-53af-b662-7578face43cc']\n",
      "Number of total tokens: 82\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'patient_name': 'alexis sparks', 'date_of_service': '20250215', 'version': '1.0'}\n",
      "### Vital Signs (Recorded on 2023-10-20)\n",
      "* Blood Pressure: 145/95 mmHg\n",
      "* Heart Rate: 82 bpm\n",
      "* Respiratory Rate: 18 breaths/min\n",
      "* Temperature: 98.6 °F\n",
      "* Oxygen Saturat<PHI>XXXX</PHI> \n",
      "* BMI: 42.1 kg/m²\n",
      "\n",
      "f30a4fe8-cacb-5934-ad3e-5c4b332660b3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document id added: ['f30a4fe8-cacb-5934-ad3e-5c4b332660b3']\n",
      "Number of total tokens: 40\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'patient_name': 'alexis sparks', 'date_of_service': '20250215', 'version': '1.0'}\n",
      "### Family History\n",
      "* Father: Hypertension, Type 2 Diabetes\n",
      "* Mother: Morbid Obesity, Hyperlipidemia\n",
      "* Siblings: One brother with obesity-related health issues\n",
      "\n",
      "fc9b759f-d60d-5f37-abb3-9970dd918be0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document id added: ['fc9b759f-d60d-5f37-abb3-9970dd918be0']\n",
      "Number of total tokens: 43\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'patient_name': 'alexis sparks', 'date_of_service': '20250215', 'version': '1.0'}\n",
      "### Medical History\n",
      "* Chronic Conditions:\n",
      "    * Morbid Obesity\n",
      "    * Hypertension\n",
      "* Previous Surgeries:\n",
      "    * None\n",
      "* Allergies:\n",
      "    * Penicillin (rash)\n",
      "\n",
      "3e688184-194b-5601-aaf8-39d01cdf0791\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document id added: ['3e688184-194b-5601-aaf8-39d01cdf0791']\n",
      "Number of total tokens: 14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'patient_name': 'alexis sparks', 'date_of_service': '20250215', 'version': '1.0'}\n",
      "### Current Medications\n",
      "* Lisinopril 20 mg daily\n",
      "4d148327-363b-515f-ad47-97643ea49288\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document id added: ['4d148327-363b-515f-ad47-97643ea49288']\n",
      "Number of total tokens: 9\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'patient_name': 'alexis sparks', 'date_of_service': '20250215', 'version': '1.0'}\n",
      "* Metformin 500 mg twice daily\n",
      "98a963dc-9ee6-5512-9b1b-e58fbd98fc14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document id added: ['98a963dc-9ee6-5512-9b1b-e58fbd98fc14']\n",
      "Number of total tokens: 25\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'patient_name': 'alexis sparks', 'date_of_service': '20250215', 'version': '1.0'}\n",
      "### Health Conditions\n",
      "* Type 2 Diabetes (recently diagnosed)\n",
      "* Obstructive Sleep Apnea (OSA)\n",
      "fc9ec1bf-3511-554b-bc97-a1b3cb936a2f\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document id added: ['fc9ec1bf-3511-554b-bc97-a1b3cb936a2f']\n",
      "Number of total tokens: 20\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'patient_name': 'alexis sparks', 'date_of_service': '20250215', 'version': '1.0'}\n",
      "### Recent Diagnosis\n",
      "* Morbid Obesity\n",
      "* Essential Hypertension\n",
      "* Type 2 Diabetes\n",
      "6154c78e-4853-51d0-95a6-9dd1118a9cbf\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document id added: ['6154c78e-4853-51d0-95a6-9dd1118a9cbf']\n",
      "Number of total tokens: 102\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'patient_name': 'alexis sparks', 'date_of_service': '20250215', 'version': '1.0'}\n",
      "### Personal Health Assessment\n",
      "* Lifestyle:\n",
      "    * Exercises: Rarely; sedentary lifestyle\n",
      "    * Diet: High in carbohydrates and sugars; minimal fruits and vegetables\n",
      "    * Sleep: 5-6 hours per night, often interrupted\n",
      "    * Stress: Moderate to high due to work and personal life\n",
      "* Tobacco Use: Never smoked\n",
      "* Alcohol Use: Social drinker, approximately 2-3 drinks per week\n",
      "* Occupation: Office manager, primarily desk job with limited physical activity\n",
      "\n",
      "7ec78bce-59b5-5b96-867d-45b034da2298\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document id added: ['7ec78bce-59b5-5b96-867d-45b034da2298']\n",
      "Number of total tokens: 90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'patient_name': 'alexis sparks', 'date_of_service': '20250215', 'version': '1.0'}\n",
      "### Physician's Notes\n",
      "* Patient presents with a significant risk for cardiovascular disease given his morbid obesity and\n",
      "hypertension. Discussed the importance of lifestyle modifications including diet changes and\n",
      "increased physical activity. Referral to a dietitian provided to assist with meal planning.\n",
      "Recommended follow-up in 3 months for reassessment of weight and blood pressure. Consider\n",
      "eligibility for bariatric surgery based on weight loss progress. Monitoring of blood\n",
      "09010f21-0497-5428-9578-b3cfa0695540\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document id added: ['09010f21-0497-5428-9578-b3cfa0695540']\n"
     ]
    }
   ],
   "source": [
    "for split_num, each_page in enumerate(all_splits):\n",
    "    page_content = each_page.page_content\n",
    "    page_content = redact_dob(page_content)\n",
    "    page_content = redact_name(page_content)\n",
    "    page_content = redact_name_references(page_content)\n",
    "    get_num_token(page_content)\n",
    "    load_document_embeddings(page_content, pat_name, dos, split_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15d361c2-6568-48cd-b5c1-0bf7b33360bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* ### Recent Diagnosis\n",
      "* Morbid Obesity\n",
      "* Essential Hypertension\n",
      "* Type 2 Diabetes [{'date_of_service': '20250215', 'patient_name': 'alexis sparks', 'version': '1.0'}]\n",
      "* ### Health Conditions\n",
      "* Type 2 Diabetes (recently diagnosed)\n",
      "* Obstructive Sleep Apnea (OSA) [{'date_of_service': '20250215', 'patient_name': 'alexis sparks', 'version': '1.0'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"do patient ever dignosed with diabetes\",\n",
    "    k=2,\n",
    "    filter={\"patient_name\": \"alexis sparks\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0bfa0dea-3c44-47b9-8118-b407426d164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* ### Recent Diagnosis\n",
      "* Morbid Obesity\n",
      "* Essential Hypertension\n",
      "* Type 2 Diabetes [{'date_of_service': '20250215', 'patient_name': 'alexis sparks', 'version': '1.0'}]\n",
      "* ### Health Conditions\n",
      "* Type 2 Diabetes (recently diagnosed)\n",
      "* Obstructive Sleep Apnea (OSA) [{'date_of_service': '20250215', 'patient_name': 'alexis sparks', 'version': '1.0'}]\n"
     ]
    }
   ],
   "source": [
    "filter = {\n",
    "    \"$and\": [\n",
    "        {\n",
    "            \"patient_name\": {\n",
    "                \"$eq\": \"alexis sparks\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"date_of_service\": {\n",
    "                \"$eq\": \"20250215\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "results = vector_store.similarity_search(\n",
    "    \"do patient ever dignosed with diabetes\",\n",
    "    k=2,\n",
    "    filter=filter,\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475b5e2b-1d95-4c79-b6ec-4f807cf1b084",
   "metadata": {},
   "source": [
    "### Vector DB is loaded, now use Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d7d852-5a5f-4f05-bbf0-e7f85efa694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3fe5fa-06af-4442-99ae-8f5ace900cb3",
   "metadata": {},
   "source": [
    "#### With RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec3b590-f9db-4a11-bf0b-ebe36607c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import RetrievalQA\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bf124c0-7039-4b61-9c40-86a5d9a066c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\"\"\"\n",
    "\n",
    "template = \"You are a bot that answers questions from a patients electronic health ecord or charts.\\n\\\n",
    "            If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\\n",
    "            {context}\\n\\\n",
    "            Question: {question}\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(\n",
    "    template=template,\n",
    "    # input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "143a944b-dec9-47af-9c37-82ab4b38b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4221e7b6-e685-44b2-901e-e828f6ce00d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question:  whats is the blood pressure of Name:alexis sparks dos:20250215\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58ea46f9-0c41-417f-9949-a2939a6ce4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = question.lower().split(\"name:\")[-1].split(\"\\n\")[0].split(\"dos:\")[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b57632c8-6c80-4065-be22-0d240e611e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dos = question.lower().split(\"name:\")[-1].split(\"\\n\")[0].split(\"dos:\")[-1].split(\"\\n\")[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25c00ac6-22f1-4647-a373-3d80986afde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_question = question.lower().split(\"name:\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75bdf895-bef5-4384-9cbb-5d342390ead5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('alexis sparks', '20250215', 'whats is the blood pressure of ')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name,dos,formatted_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f22c24be-36cc-455a-8631-d42a28878478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a bot that answers questions from a patients electronic health ecord or charts.\\n            If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n            ### Vital Signs (Recorded on 2023-10-20)\\n* Blood Pressure: 145/95 mmHg\\n* Heart Rate: 82 bpm\\n* Respiratory Rate: 18 breaths/min\\n* Temperature: 98.6 °F\\n* Oxygen Saturat<PHI>XXXX</PHI> \\n* BMI: 42.1 kg/m²\\n\\n\\n### Current Medications\\n* Lisinopril 20 mg daily\\n            Question: whats is the blood pressure of \""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieved_docs = vector_store.similarity_search(question)\n",
    "filter = {\n",
    "    \"$and\": [\n",
    "        {\n",
    "            \"patient_name\": {\n",
    "                \"$eq\": name\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"date_of_service\": {\n",
    "                \"$eq\": str(dos)\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(\n",
    "    question,\n",
    "    k=2,\n",
    "    filter=filter,\n",
    ")\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "doc_source = [doc.page_content for doc in retrieved_docs]\n",
    "# docs_content\n",
    "# custom_rag_prompt.format(context=docs_content, question=formatted_question)\n",
    "prompt = custom_rag_prompt.invoke({\"question\": formatted_question, \"context\": docs_content})\n",
    "answer = llm.invoke(prompt)\n",
    "# prompt\n",
    "# custom_rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc266b6c-02df-4e89-bc5c-0d95e3664819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The blood pressure recorded is 145/95 mmHg.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b652378-3b59-45ba-aacb-56240d1508b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43227551-e71b-4352-87f2-0805b370a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"patient_name\",\n",
    "        description=\"The name of the patient\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"date_of_service\",\n",
    "        description=\"The date when patient receied services or service date or date of service in yyymmdd format\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"chart or electronic health record of patients\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a6a210a-21f8-4c85-bb65-5f4dde8bfc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vector_store,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9c77713-da6b-4844-8a86-e04cf873719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"What is th blood pressure of alexis sparks\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c5d8e-55ca-49d8-ac64-0c231273b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "# docs_content\n",
    "# custom_rag_prompt.format(context=docs_content, question=formatted_question)\n",
    "prompt = custom_rag_prompt.invoke({\"question\": formatted_question, \"context\": docs_content})\n",
    "answer = llm.invoke(prompt)\n",
    "# prompt\n",
    "# custom_rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16337306-adf1-4b4c-92e0-65eaffce3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_with_source = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     chain_type=\"stuff\",\n",
    "#     retriever=store.as_retriever(),\n",
    "#     chain_type_kwargs={\"prompt\": PROMPT, },\n",
    "#     return_source_documents=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e6d44-c31a-41e6-9a85-3640c788464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(\n",
    "#     qa_with_source(\"How many people were killed in southern california wildfire in January 2025?\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9358c0a-0440-4bf6-951a-9b1ecfd672cc",
   "metadata": {},
   "source": [
    "RAG approach is working as expected. LLM was able to accurately answer the question that southern California wildfires in January 2025 \"killed at least 27 people\". As we see above that the prompt includes the information about the southern california wildfires from the Wikipedia in the `context`. The `retriever` first retrived the context information from the vector database that closely matches the user question and then included it as part of the prompt for the LLM call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e18e6d7-f961-498b-a76d-dfc5c1006ece",
   "metadata": {},
   "source": [
    "#### Without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82b563-32c3-40b8-9a7f-a2d21d4ba66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# document_1 = Document(\n",
    "#     page_content=page_content,\n",
    "#     metadata={\n",
    "#         \"patient_name\": pat_name,\n",
    "#         \"date_of_service\":dos,\n",
    "#         \"version\":\"1.0\"\n",
    "#     },\n",
    "#     id=hash(f\"{pat_name}-{dos}-{split_num}\"),\n",
    "# )\n",
    "\n",
    "# document_2 = Document(\n",
    "#     page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "#     metadata={\"source\": \"news\"},\n",
    "#     id=2,\n",
    "# )\n",
    "\n",
    "# document_3 = Document(\n",
    "#     page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "#     metadata={\"source\": \"tweet\"},\n",
    "#     id=3,\n",
    "# )\n",
    "\n",
    "# document_4 = Document(\n",
    "#     page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "#     metadata={\"source\": \"news\"},\n",
    "#     id=4,\n",
    "# )\n",
    "\n",
    "# document_5 = Document(\n",
    "#     page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "#     metadata={\"source\": \"tweet\"},\n",
    "#     id=5,\n",
    "# )\n",
    "\n",
    "# document_6 = Document(\n",
    "#     page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "#     metadata={\"source\": \"website\"},\n",
    "#     id=6,\n",
    "# )\n",
    "\n",
    "# document_7 = Document(\n",
    "#     page_content=\"The top 10 soccer players in the world right now.\",\n",
    "#     metadata={\"source\": \"website\"},\n",
    "#     id=7,\n",
    "# )\n",
    "\n",
    "# document_8 = Document(\n",
    "#     page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "#     metadata={\"source\": \"tweet\"},\n",
    "#     id=8,\n",
    "# )\n",
    "\n",
    "# document_9 = Document(\n",
    "#     page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "#     metadata={\"source\": \"news\"},\n",
    "#     id=9,\n",
    "# )\n",
    "\n",
    "# document_10 = Document(\n",
    "#     page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "#     metadata={\"source\": \"tweet\"},\n",
    "#     id=10,\n",
    "# )\n",
    "\n",
    "# documents = [\n",
    "#     document_1,\n",
    "#     # document_2,\n",
    "#     # document_3,\n",
    "#     # document_4,\n",
    "#     # document_5,\n",
    "#     # document_6,\n",
    "#     # document_7,\n",
    "#     # document_8,\n",
    "#     # document_9,\n",
    "#     # document_10,\n",
    "# ]\n",
    "# uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "# vector_store.add_documents(documents=documents, ids=uuids)\n",
    "# vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a00dd-971f-4f38-91ca-661c42ddcde2",
   "metadata": {},
   "source": [
    "Question 2: How many widfires have affected the Los Angeles metropolitan area in 2025?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc61a1-c8a6-4053-bade-1bec22a37453",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": f\"You are a bot that answers questions about January 2025 Southern California wildfires.\\n\\\n",
    "            If you donot know the answer, simply state that you donot know.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"Q: How many widfires have affected the Los Angeles metropolitan area in 2025?\\nA:\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e40a71-159d-4a0c-bdc5-fefd32fc10d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50826ed-ac6c-4a6c-af6c-69ef1fcb3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Response from LLM without RAG:\\n {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e244400-efad-4764-95ab-66f0dcc52f38",
   "metadata": {},
   "source": [
    "Same observation as question 1, OpenAI LLM was not able to answer the question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eac5f1-3f39-46dd-957a-15f341196286",
   "metadata": {},
   "source": [
    "#### With RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6069d-59c2-48d5-bc3c-858b97a7a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(\n",
    "    qa_with_source(\"How many widfires have affected the Los Angeles metropolitan area in 2025?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bdec04-3ecd-4142-958d-f11317db90ad",
   "metadata": {},
   "source": [
    "Received the corcect response from LLM about number of wildfires effecting LA in 2025 because the information about the number of wildfires effecting the LA area in 2025 is passed in the context of the prompt which is sent to LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c60d11-69c0-4fae-b3d8-ef8f51c4ffdc",
   "metadata": {},
   "source": [
    "Apart from RAG's capability to provide reponses by using information from a knowledge base, the above responses also includes the source document from which the response were based. This is another important factor in RAG approach which allows the user to trust the answer and make sure the response is grounded in the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8990575-343a-4b02-a694-f76d4c2cb793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
