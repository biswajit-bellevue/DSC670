{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e333213f-c0a5-4f58-ba16-8143d4b2aefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.prefer_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796dbf2e-1984-40e8-a373-be6faa1c5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "model = \"en_core_web_sm\"\n",
    "nlp = spacy.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520252c3-f0b0-45e2-8e25-921ef9505d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    " text = (\"This is a demonstration of text chunking with spaCy and tiktoken. \"\n",
    "        \"Using both allows for precise token counting and effective chunking. \"\n",
    "        \"Overlap and sliding window strategies are useful for various applications. \"\n",
    "        \"Choose your strategy based on your requirements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0cae5f6-01bd-4c83-9813-5d99438ddcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens: 42\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text into sentences using spaCy\n",
    "doc = nlp(text)\n",
    "print(f\"number of tokens: {len(doc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b240822f-0c3b-4a34-b003-f4dc030187d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ab4b71-a9c6-495b-9259-76c88f566e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a demonstration of text chunking with spaCy and tiktoken.',\n",
       " 'Using both allows for precise token counting and effective chunking.',\n",
       " 'Overlap and sliding window strategies are useful for various applications.',\n",
       " 'Choose your strategy based on your requirements.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1db0df-069c-48f3-8c97-842ecedf8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9b0ef05-a79f-4b2e-b8fe-3caeb37b277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63f7965d-8448-49e1-869e-ac9b8729ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 384)\n"
     ]
    }
   ],
   "source": [
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "933be896-ad4d-49b8-b2fb-bf46ceb7fcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000,  0.4432,  0.1250, -0.0208],\n",
      "        [ 0.4432,  1.0000,  0.1818,  0.0998],\n",
      "        [ 0.1250,  0.1818,  1.0000,  0.2686],\n",
      "        [-0.0208,  0.0998,  0.2686,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a805f-29a9-4b00-956e-d52ab7bc7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client for chroma db\n",
    "client = chromadb.Client()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
