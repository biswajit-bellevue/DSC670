{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b95164-6963-4658-ba23-867bfd9bf8bd",
   "metadata": {},
   "source": [
    "## Assignmen Week 4\n",
    "\n",
    "### Using Stability IO API to generate Image from text prompt and then Edit the same image to replace an Object "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5359c-a45e-4bee-8a66-b5d3b933ec2b",
   "metadata": {},
   "source": [
    "Stability AI provides acees to their `Stable Diffusion` Gen AI models allowing users to programatically geneate via API calls. The below steps demonsrates the steps to generate image using natural language convesation in `python` language imlementatation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ed5716-7dbf-4fe8-ac80-6e308e9810e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ecbbe1-bf5d-4ad8-8631-72a397bb99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get api key from file\n",
    "with open(\"../../apikeys/stabilityio-keys.json\", \"r\") as key_file:\n",
    "    api_key = json.load(key_file)[\"api_secret_key\"]\n",
    "os.environ[\"STABILITY_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7028068b-8c24-44e0-b82d-245988432603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt:  a whale jumping out of water in an ocean during sunset\n"
     ]
    }
   ],
   "source": [
    "user_prompt = input(\"Enter your prompt: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9487c09-917a-4e57-9362-1e1f46fcdf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the api key and model version\n",
    "engine_id = \"stable-diffusion-v1-6\"\n",
    "api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
    "api_key = os.getenv(\"STABILITY_API_KEY\")\n",
    "\n",
    "if api_key is None:\n",
    "    raise Exception(\"Missing Stability API key.\")\n",
    "\n",
    "# perform api call to generate image\n",
    "response = requests.post(\n",
    "    f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    },\n",
    "    json={\n",
    "        \"text_prompts\": [\n",
    "            {\n",
    "                \"text\": user_prompt\n",
    "            }\n",
    "        ],\n",
    "        \"cfg_scale\": 10,\n",
    "        \"height\": 1024,\n",
    "        \"width\": 1024,\n",
    "        \"samples\": 1, #generate only one sample image\n",
    "        \"steps\": 50,\n",
    "    },\n",
    ")\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(\"Non-200 response: \" + str(response.text))\n",
    "\n",
    "# retrieve the json object of response\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4325fa-3ddb-4456-b19b-6848247ced2c",
   "metadata": {},
   "source": [
    "Note. `cfg_scale` parameter is used to define how strictly the diffusion process will adhere to the prompt. We can set it to a higher value to generate an image strictly matching the prompt but in that case there are high chances of loss of creativity and reality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6c765af-33b5-417a-8119-8a37421430fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to store images if not exist\n",
    "image_dir = os.path.join(os.path.curdir, \"stabilityio/imgages/\")\n",
    "if os.path.exists(image_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff509705-6a46-4002-817b-4093e906d665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image filename:  ./stabilityio/imgages/v1_txt2img_0.png\n"
     ]
    }
   ],
   "source": [
    "# store images in directory received from api call\n",
    "for i, image in enumerate(data[\"artifacts\"]):\n",
    "    with open(os.path.join(image_dir,f\"v1_txt2img_{i}.png\"), \"wb\") as f:\n",
    "        print(\"image filename: \",os.path.join(image_dir,f\"v1_txt2img_{i}.png\"))\n",
    "        f.write(base64.b64decode(image[\"base64\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65cdb12-f05b-4f0a-9fee-f4b816f59d9b",
   "metadata": {},
   "source": [
    "#### Generated Image\n",
    "\n",
    "![image]( ./stabilityio/imgages/v1_txt2img_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1d378-828e-4bf2-8d2a-ff9ca0ba1af3",
   "metadata": {},
   "source": [
    "We have used Stable Diffusion version `SD v1.6` vision model for the above image generation, even though there are newer versions which has higher price tag. For the simple image generation prompt the older `SD v1.6` is working pretty well. The generated image contains the details mentioned in the prompt. It clearly shows a whale's body part jumping out of water with sunset in he background. It is impressive to notice the high quaity and resolution of the generated image, particulary the focus on the subject and bluriness of blackground just like a realistic image captured by an exprienced photographer. \n",
    "\n",
    "One important point is that even though the prompt mentioned `a whale jumping out of water`, the image `only shows the tail part out of water`. This might be because that it is more common to see images of whales with only tail out of water than the full body of the whale. Hence, the model might have got traind with more whale images having tail out of water than images with their full body. Another way we could have got image of a whale with full body jumping out of water by `explicitly instructing the vision model` to generate such images which highlights the imporatnce of explicit and correct prompts (_prompt engineering_) to generate better images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318cef6e-bbda-4c7e-a5c9-3296df53f47c",
   "metadata": {},
   "source": [
    "Stability IO provides other capabilities of visison model via API such as inpainting, search and eplace, erase objects, remove background and many more. In the below steps we have used `search-and-replace` feature to change the `whale` in the above generated image with `dolphins`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61401c1c-4e99-4bd8-a589-53c182332746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search and replace API call\n",
    "\n",
    "response = requests.post(\n",
    "    f\"https://api.stability.ai/v2beta/stable-image/edit/search-and-replace\",\n",
    "    headers={\n",
    "        \"authorization\": f\"Bearer {api_key}\",\n",
    "        \"accept\": \"image/*\"\n",
    "    },\n",
    "    files={\n",
    "        \"image\": open(\"./stabilityio/imgages/v1_txt2img_0.png\", \"rb\") #image where to replace object\n",
    "    },\n",
    "    data={\n",
    "        \"prompt\": \"a pod of dolphins jumping out of water in an ocean during sunset\",\n",
    "        \"search_prompt\": \"whale\",\n",
    "        \"output_format\": \"jpeg\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efd1b926-1928-4f95-aeac-3285199a050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store image content from api response in directory\n",
    "if response.status_code == 200:\n",
    "    with open(os.path.join(image_dir,f\"replaced_img.jpeg\"), \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "else:\n",
    "    raise Exception(str(response.json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b578406f-9538-4871-a92b-b2651439876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New filepath: ./stabilityio/imgages/replaced_img.jpeg\n"
     ]
    }
   ],
   "source": [
    "print(\"New filepath:\",os.path.join(image_dir,f\"replaced_img.jpeg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e61f191-16f3-47f1-bad1-d76f4c33003e",
   "metadata": {},
   "source": [
    "#### New modified Image\n",
    "![image](./stabilityio/imgages/replaced_img.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c1fbe-a14c-40b8-9e01-49d96819ca99",
   "metadata": {},
   "source": [
    "The results of `search an replace` task by the Stable Diffusion model is very impressive. The `whale` is entirely replaced by `dolphins` in the resulting image without any noticeable noise or degragradation in the quality of the picture. Only the whale got replaced with a pod of dolphins as instructed in the prompt without any changes in other parts of the image like the ocean and the background sunset remains as is. The whale got replaced as if it never existed before which is quite amazing. However we notice the water splash caused by the whale's tiail from previous image is still remianing in the modified image because the input prompt didn't mention to remove the water splash.\n",
    "\n",
    "One important thing to notice in the modified image is that this time the `whole body of the dolphins is out of water` unlike `only the tail` in case of whale in previous image. This is mostly because it is quite natural for dolphins to jump entirely out of water and hence it is highly prabable that the model was trained on similar images. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
